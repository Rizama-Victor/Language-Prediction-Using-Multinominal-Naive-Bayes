{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e7dbfcd-ba50-4d52-84fe-380d01d10201",
   "metadata": {},
   "source": [
    "# Language Prediction Using Multinominal Naive Bayes\n",
    "\n",
    "The following project is focused on building a machine learning model that can accurately detect languages including: `English`, `French`, `Spanish` and `German`. The dataset used for this project was sourced from [Language Detection](https://www.kaggle.com/datasets/zarajamshaid/language-identification-datasst).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3360e5c3-c923-4496-a0c8-2ff62139f351",
   "metadata": {},
   "source": [
    "### Importation of Necessary Libaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "id": "00639243-af90-4b19-8c05-29e476cd67e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports pandas library for working with Dataframe\n",
    "import pandas as pd\n",
    "\n",
    "# import numpy library for working with arrays\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# imports seaborn library\n",
    "import seaborn as sns\n",
    "\n",
    "# imports the label encoder library\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# imports train-test-split and Grid Search library for splitting the dataset(s)\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "# imports naive bias algorithm from sklearn\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# imports all necessary evaluation metrics from sklearn\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "# imports joblib for model saving\n",
    "import joblib\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ae45f5-4b37-494a-bb7f-389b5efac80f",
   "metadata": {},
   "source": [
    "### Reads the CSV File(s) into a Dataframe\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "id": "412e789e-4f87-477b-bd8c-5ed76e28bc00",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Language Detection.csv\", encoding='ISO-8859-1')  # Load the dataset into the DataFrame 'df' using ISO-8859-1 encoding to handle special character"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "510584c0-f569-40d0-98d8-21eb17a77343",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "id": "68fea86f-ad2d-41b7-a809-0fd5b24baefb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Language</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "      <th>Unnamed: 5</th>\n",
       "      <th>Unnamed: 6</th>\n",
       "      <th>Unnamed: 7</th>\n",
       "      <th>Unnamed: 8</th>\n",
       "      <th>Unnamed: 9</th>\n",
       "      <th>Unnamed: 10</th>\n",
       "      <th>Unnamed: 11</th>\n",
       "      <th>Unnamed: 12</th>\n",
       "      <th>Unnamed: 13</th>\n",
       "      <th>Unnamed: 14</th>\n",
       "      <th>Unnamed: 15</th>\n",
       "      <th>Unnamed: 16</th>\n",
       "      <th>Unnamed: 17</th>\n",
       "      <th>Unnamed: 18</th>\n",
       "      <th>Unnamed: 19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nature, in the broadest sense, is the natural...</td>\n",
       "      <td>English</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"Nature\" can refer to the phenomena of the phy...</td>\n",
       "      <td>English</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The study of nature is a large, if not the onl...</td>\n",
       "      <td>English</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Although humans are part of nature, human acti...</td>\n",
       "      <td>English</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[1] The word nature is borrowed from the Old F...</td>\n",
       "      <td>English</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text Language Unnamed: 2  \\\n",
       "0   Nature, in the broadest sense, is the natural...  English        NaN   \n",
       "1  \"Nature\" can refer to the phenomena of the phy...  English        NaN   \n",
       "2  The study of nature is a large, if not the onl...  English        NaN   \n",
       "3  Although humans are part of nature, human acti...  English        NaN   \n",
       "4  [1] The word nature is borrowed from the Old F...  English        NaN   \n",
       "\n",
       "  Unnamed: 3 Unnamed: 4 Unnamed: 5 Unnamed: 6 Unnamed: 7 Unnamed: 8  \\\n",
       "0        NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "1        NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "2        NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "3        NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "4        NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "\n",
       "  Unnamed: 9 Unnamed: 10 Unnamed: 11 Unnamed: 12 Unnamed: 13 Unnamed: 14  \\\n",
       "0        NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "1        NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "2        NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "3        NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "4        NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "\n",
       "  Unnamed: 15 Unnamed: 16 Unnamed: 17 Unnamed: 18 Unnamed: 19  \n",
       "0         NaN         NaN         NaN         NaN         NaN  \n",
       "1         NaN         NaN         NaN         NaN         NaN  \n",
       "2         NaN         NaN         NaN         NaN         NaN  \n",
       "3         NaN         NaN         NaN         NaN         NaN  \n",
       "4         NaN         NaN         NaN         NaN         NaN  "
      ]
     },
     "execution_count": 405,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head() # displays first 5 rows of the dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "id": "ee57a90c-a535-485e-9f0d-faada772acfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13339, 20)\n"
     ]
    }
   ],
   "source": [
    "# displays out the shape of the data\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90780669-ebb0-40e8-a613-148d7a63bf56",
   "metadata": {},
   "source": [
    "#### Describing the Data Using Statistical Terms (i.e., Summary Statistics)\r\n",
    "\r\n",
    "- **Count**: The total number of non-null observations in each feature column.\r\n",
    "- **Unique**: The number of distinct values present in each column, indicating the diversity of the data.\r\n",
    "- **Top**: The most frequently occurring value in the column, helping to identify the most common entry.\r\n",
    "- **Freq**: The frequency of the top value, showing how many times the most common value appears in the col data.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "id": "d79f134c-2dee-43d3-89f6-b955e18a9062",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Language</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "      <th>Unnamed: 5</th>\n",
       "      <th>Unnamed: 6</th>\n",
       "      <th>Unnamed: 7</th>\n",
       "      <th>Unnamed: 8</th>\n",
       "      <th>Unnamed: 9</th>\n",
       "      <th>Unnamed: 10</th>\n",
       "      <th>Unnamed: 11</th>\n",
       "      <th>Unnamed: 12</th>\n",
       "      <th>Unnamed: 13</th>\n",
       "      <th>Unnamed: 14</th>\n",
       "      <th>Unnamed: 15</th>\n",
       "      <th>Unnamed: 16</th>\n",
       "      <th>Unnamed: 17</th>\n",
       "      <th>Unnamed: 18</th>\n",
       "      <th>Unnamed: 19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>13338</td>\n",
       "      <td>13337</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>13251</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>lÃ©volution du nombre dhabitants est connue Ã ...</td>\n",
       "      <td>English</td>\n",
       "      <td>à¤à¤¬ à¤à¤¨à¤¸à¥ à¤ªà¥à¤à¤¾ à¤à¤¯à¤¾ à¤...</td>\n",
       "      <td>à¤¤à¥ à¤µà¤¹ à¤",
       "à¤à¤²à¥ à¤¬à¤¾à¤° à¤ªà¥à¤...</td>\n",
       "      <td>à¤®à¥à¤°à¥ à¤ªà¤¾à¤¸ à¤¶à¤¨à¤¿à¤µà¤¾à¤° à¤...</td>\n",
       "      <td>à¤«à¤¿à¤²à¥à¤®à¥à¤ à¤à¥ à¤²à¤¿à¤ à¤à¤...</td>\n",
       "      <td>à¤",
       "à¤¬ à¤à¥à¤ à¤¸à¤à¤à¥à¤·à¤¿à¤ªà¥à¤¤ ...</td>\n",
       "      <td>à¤­à¤²à¥ à¤¹à¥ à¤",
       "à¤¬ à¤à¤ª à¤à¤¿à¤¸à¥ à...</td>\n",
       "      <td>à¤à¤¸à¤²à¤¿à¤ à¤¯à¤¦à¤¿ à¤à¤ªà¤à¥ à¤ªà¤¾...</td>\n",
       "      <td>à¤¤à¥ à¤à¤ª à¤¨à¤¿à¤¶à¥à¤à¤¿à¤¤ à¤°à¥à¤ª...</td>\n",
       "      <td>à¤à¥ à¤à¤¿ à¤à¤ªà¤¤à¥à¤¤à¤¿à¤à¤¨à¤ à¤¹à¥</td>\n",
       "      <td>à¤¯à¤¹ à¤à¤ à¤",
       "à¤ªà¤®à¤¾à¤¨ à¤¹à¥ à¤à¤¿à¤...</td>\n",
       "      <td>à¤²à¥à¤à¤¿à¤¨ 180 à¤¡à¤¿à¤à¥à¤°à¥ à¤¸à¥...</td>\n",
       "      <td>à¤²à¥à¤à¤¿à¤¨ à¤®à¥à¤à¥ à¤¨à¤¹à¥à¤ à¤ª...</td>\n",
       "      <td>à¤§à¥à¤®à¥ à¤§à¥à¤®à¥ à¤à¤²à¤¨à¥ à¤à¥...</td>\n",
       "      <td>à¤¸à¥à¤¸à¥à¤¤ à¤¹à¥ à¤¸à¤à¤¤à¥ à¤¹à¥à¤...</td>\n",
       "      <td>à¤à¤¸à¤²à¤¿à¤ à¤µà¥ 10 à¤¸à¥à¤®à¤¾à¤°à¥à...</td>\n",
       "      <td>à¤à¤¸ à¤¸à¥à¤ªà¥à¤à¤° à¤ªà¤° à¤à¥à¤²à¤¿...</td>\n",
       "      <td>à¤à¤ª à¤à¤¸à¤à¤¾ à¤ªà¥à¤°à¥ à¤¤à¤°à¤¹ à¤...</td>\n",
       "      <td>Hindi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>7</td>\n",
       "      <td>2385</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     Text Language  \\\n",
       "count                                               13338    13337   \n",
       "unique                                              13251       18   \n",
       "top     lÃ©volution du nombre dhabitants est connue Ã ...  English   \n",
       "freq                                                    7     2385   \n",
       "\n",
       "                                               Unnamed: 2  \\\n",
       "count                                                   1   \n",
       "unique                                                  1   \n",
       "top      à¤à¤¬ à¤à¤¨à¤¸à¥ à¤ªà¥à¤à¤¾ à¤à¤¯à¤¾ à¤...   \n",
       "freq                                                    1   \n",
       "\n",
       "                                               Unnamed: 3  \\\n",
       "count                                                   1   \n",
       "unique                                                  1   \n",
       "top      à¤¤à¥ à¤µà¤¹ à¤\n",
       "à¤à¤²à¥ à¤¬à¤¾à¤° à¤ªà¥à¤...   \n",
       "freq                                                    1   \n",
       "\n",
       "                                               Unnamed: 4  \\\n",
       "count                                                   1   \n",
       "unique                                                  1   \n",
       "top      à¤®à¥à¤°à¥ à¤ªà¤¾à¤¸ à¤¶à¤¨à¤¿à¤µà¤¾à¤° à¤...   \n",
       "freq                                                    1   \n",
       "\n",
       "                                               Unnamed: 5  \\\n",
       "count                                                   1   \n",
       "unique                                                  1   \n",
       "top      à¤«à¤¿à¤²à¥à¤®à¥à¤ à¤à¥ à¤²à¤¿à¤ à¤à¤...   \n",
       "freq                                                    1   \n",
       "\n",
       "                                               Unnamed: 6  \\\n",
       "count                                                   1   \n",
       "unique                                                  1   \n",
       "top      à¤\n",
       "à¤¬ à¤à¥à¤ à¤¸à¤à¤à¥à¤·à¤¿à¤ªà¥à¤¤ ...   \n",
       "freq                                                    1   \n",
       "\n",
       "                                               Unnamed: 7  \\\n",
       "count                                                   1   \n",
       "unique                                                  1   \n",
       "top      à¤­à¤²à¥ à¤¹à¥ à¤\n",
       "à¤¬ à¤à¤ª à¤à¤¿à¤¸à¥ à...   \n",
       "freq                                                    1   \n",
       "\n",
       "                                               Unnamed: 8  \\\n",
       "count                                                   1   \n",
       "unique                                                  1   \n",
       "top      à¤à¤¸à¤²à¤¿à¤ à¤¯à¤¦à¤¿ à¤à¤ªà¤à¥ à¤ªà¤¾...   \n",
       "freq                                                    1   \n",
       "\n",
       "                                               Unnamed: 9  \\\n",
       "count                                                   1   \n",
       "unique                                                  1   \n",
       "top      à¤¤à¥ à¤à¤ª à¤¨à¤¿à¤¶à¥à¤à¤¿à¤¤ à¤°à¥à¤ª...   \n",
       "freq                                                    1   \n",
       "\n",
       "                                              Unnamed: 10  \\\n",
       "count                                                   1   \n",
       "unique                                                  1   \n",
       "top      à¤à¥ à¤à¤¿ à¤à¤ªà¤¤à¥à¤¤à¤¿à¤à¤¨à¤ à¤¹à¥   \n",
       "freq                                                    1   \n",
       "\n",
       "                                              Unnamed: 11  \\\n",
       "count                                                   1   \n",
       "unique                                                  1   \n",
       "top      à¤¯à¤¹ à¤à¤ à¤\n",
       "à¤ªà¤®à¤¾à¤¨ à¤¹à¥ à¤à¤¿à¤...   \n",
       "freq                                                    1   \n",
       "\n",
       "                                              Unnamed: 12  \\\n",
       "count                                                   1   \n",
       "unique                                                  1   \n",
       "top      à¤²à¥à¤à¤¿à¤¨ 180 à¤¡à¤¿à¤à¥à¤°à¥ à¤¸à¥...   \n",
       "freq                                                    1   \n",
       "\n",
       "                                              Unnamed: 13  \\\n",
       "count                                                   1   \n",
       "unique                                                  1   \n",
       "top      à¤²à¥à¤à¤¿à¤¨ à¤®à¥à¤à¥ à¤¨à¤¹à¥à¤ à¤ª...   \n",
       "freq                                                    1   \n",
       "\n",
       "                                              Unnamed: 14  \\\n",
       "count                                                   1   \n",
       "unique                                                  1   \n",
       "top      à¤§à¥à¤®à¥ à¤§à¥à¤®à¥ à¤à¤²à¤¨à¥ à¤à¥...   \n",
       "freq                                                    1   \n",
       "\n",
       "                                              Unnamed: 15  \\\n",
       "count                                                   1   \n",
       "unique                                                  1   \n",
       "top      à¤¸à¥à¤¸à¥à¤¤ à¤¹à¥ à¤¸à¤à¤¤à¥ à¤¹à¥à¤...   \n",
       "freq                                                    1   \n",
       "\n",
       "                                              Unnamed: 16  \\\n",
       "count                                                   1   \n",
       "unique                                                  1   \n",
       "top      à¤à¤¸à¤²à¤¿à¤ à¤µà¥ 10 à¤¸à¥à¤®à¤¾à¤°à¥à...   \n",
       "freq                                                    1   \n",
       "\n",
       "                                              Unnamed: 17  \\\n",
       "count                                                   1   \n",
       "unique                                                  1   \n",
       "top      à¤à¤¸ à¤¸à¥à¤ªà¥à¤à¤° à¤ªà¤° à¤à¥à¤²à¤¿...   \n",
       "freq                                                    1   \n",
       "\n",
       "                                              Unnamed: 18 Unnamed: 19  \n",
       "count                                                   1           1  \n",
       "unique                                                  1           1  \n",
       "top      à¤à¤ª à¤à¤¸à¤à¤¾ à¤ªà¥à¤°à¥ à¤¤à¤°à¤¹ à¤...       Hindi  \n",
       "freq                                                    1           1  "
      ]
     },
     "execution_count": 408,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe() # describes the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa69886-81ca-4e0f-9d75-c956d29bdd0d",
   "metadata": {},
   "source": [
    "#### Summarizing the Dataframe's Structure\n",
    "\n",
    "- Provides a concise summary of the DataFrame.\n",
    "- Displays the total number of rows (entries) which could help in detecting missing values.\n",
    "- Shows the number of non-null values in each column.\n",
    "- Lists the data types of each column (e.g., int64, float64, object for categorical data).\n",
    "- Gives the memory usage of the DataFrame.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "id": "79ff342c-8434-4bb3-82e2-6b4984b31f3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 13339 entries, 0 to 13338\n",
      "Data columns (total 20 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   Text         13338 non-null  object\n",
      " 1   Language     13337 non-null  object\n",
      " 2   Unnamed: 2   1 non-null      object\n",
      " 3   Unnamed: 3   1 non-null      object\n",
      " 4   Unnamed: 4   1 non-null      object\n",
      " 5   Unnamed: 5   1 non-null      object\n",
      " 6   Unnamed: 6   1 non-null      object\n",
      " 7   Unnamed: 7   1 non-null      object\n",
      " 8   Unnamed: 8   1 non-null      object\n",
      " 9   Unnamed: 9   1 non-null      object\n",
      " 10  Unnamed: 10  1 non-null      object\n",
      " 11  Unnamed: 11  1 non-null      object\n",
      " 12  Unnamed: 12  1 non-null      object\n",
      " 13  Unnamed: 13  1 non-null      object\n",
      " 14  Unnamed: 14  1 non-null      object\n",
      " 15  Unnamed: 15  1 non-null      object\n",
      " 16  Unnamed: 16  1 non-null      object\n",
      " 17  Unnamed: 17  1 non-null      object\n",
      " 18  Unnamed: 18  1 non-null      object\n",
      " 19  Unnamed: 19  1 non-null      object\n",
      "dtypes: object(20)\n",
      "memory usage: 2.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info() # displays the summary of the dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b9702e-4ed0-4254-93ab-d0c956314a2c",
   "metadata": {},
   "source": [
    "### Checking for Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "id": "aeb8a2e7-cfec-4b4a-b9f0-fc0fdc435eee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "List of Columns in the Dataframe with Missing Values: \n",
      "\n",
      "['Text', 'Language', 'Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4', 'Unnamed: 5', 'Unnamed: 6', 'Unnamed: 7', 'Unnamed: 8', 'Unnamed: 9', 'Unnamed: 10', 'Unnamed: 11', 'Unnamed: 12', 'Unnamed: 13', 'Unnamed: 14', 'Unnamed: 15', 'Unnamed: 16', 'Unnamed: 17', 'Unnamed: 18', 'Unnamed: 19']\n",
      "\n",
      "Number of Columns in the Dataframe with Missing Values:\n",
      "\n",
      "20\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "missing_col_lst = df.columns[df.isnull().any()].tolist() # checks all columns in the dataframe for missing values and stores the column name in a list.\n",
    "\n",
    "print(f\"\"\"\n",
    "List of Columns in the Dataframe with Missing Values: \n",
    "\n",
    "{missing_col_lst}\n",
    "\n",
    "Number of Columns in the Dataframe with Missing Values:\n",
    "\n",
    "{len(missing_col_lst)}\n",
    "\n",
    "\"\"\") # prints the list and number of all columns that have missing values.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d9695b-7565-493c-82d9-31599bf9292e",
   "metadata": {},
   "source": [
    "##### Observation\n",
    "\n",
    "The analysis revealed that all of the 20 columns contained missing values. Consequently, all columns with missing values will be handled dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1fd4d80-ec38-477d-829b-8d7b2acc1dcb",
   "metadata": {},
   "source": [
    "### Handling Missing Values\r\n",
    "\r\n",
    "Missing values in categorical columns are usually filled with the mode, while numerical columns are often imputed with the mean or median. However, filling a missing `Language` value with the most common entry (\"English\") may misrepresent the data and negatively impact model performance. Therefore, it's best to remove rows with missing values in the `Language` column, especially since only one row is affected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "id": "2fea5076-6120-414a-863d-070c4bc04804",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[[\"Text\", \"Language\"]].dropna(subset=[\"Language\", \"Text\"]) # keeps only the \"Text\" and \"Language\" columns while removing all rows where \"Language\" and \"Text\" column has an empty value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "id": "928dff85-22fb-4482-a8ba-8bac20074875",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nature, in the broadest sense, is the natural...</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"Nature\" can refer to the phenomena of the phy...</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The study of nature is a large, if not the onl...</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Although humans are part of nature, human acti...</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[1] The word nature is borrowed from the Old F...</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13334</th>\n",
       "      <td>notices dans des bases relatives au sport  ass...</td>\n",
       "      <td>French</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13335</th>\n",
       "      <td>el investigador ha recibido varios reconocimie...</td>\n",
       "      <td>Spanish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13336</th>\n",
       "      <td>le village est une station familiale de sports...</td>\n",
       "      <td>French</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13337</th>\n",
       "      <td>hors du terrain les annÃ©es  et  sont des annÃ...</td>\n",
       "      <td>French</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13338</th>\n",
       "      <td>con motivo de la celebraciÃ³n del septuagÃ©sim...</td>\n",
       "      <td>Spanish</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13337 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Text Language\n",
       "0       Nature, in the broadest sense, is the natural...  English\n",
       "1      \"Nature\" can refer to the phenomena of the phy...  English\n",
       "2      The study of nature is a large, if not the onl...  English\n",
       "3      Although humans are part of nature, human acti...  English\n",
       "4      [1] The word nature is borrowed from the Old F...  English\n",
       "...                                                  ...      ...\n",
       "13334  notices dans des bases relatives au sport  ass...   French\n",
       "13335  el investigador ha recibido varios reconocimie...  Spanish\n",
       "13336  le village est une station familiale de sports...   French\n",
       "13337  hors du terrain les annÃ©es  et  sont des annÃ...   French\n",
       "13338  con motivo de la celebraciÃ³n del septuagÃ©sim...  Spanish\n",
       "\n",
       "[13337 rows x 2 columns]"
      ]
     },
     "execution_count": 416,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df # displays the modified dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d16fce-3866-4232-8ad6-191d2977544f",
   "metadata": {},
   "source": [
    "### Data Pre-processing\n",
    "\n",
    "This section focuses on retaining only the rows that contain the languages of interest for detection. The Languages are:\n",
    "- English\n",
    "- French\n",
    "- Spanish AND\n",
    "- Deutsch / German\n",
    "\n",
    "The Dataframe will be filtered accordingly to achieve this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "id": "ad4411e5-66b2-49ac-8c85-48862f7671dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['English' 'Malayalam' 'Hindi'\n",
      " \" à¤\\x85à¤¬ à¤\\x86à¤ª à¤¸à¥\\x8bà¤\\x9a à¤¸à¤\\x95à¤¤à¥\\x87 à¤¹à¥\\x88à¤\\x82 à¤\\x95à¤¿ à¤¶à¤¬à¥\\x8dà¤¦ à¤«à¤¿à¤\\x95à¥\\x8dà¤¸ à¤\\x95à¤¾ à¤\\x95à¥\\x81à¤\\x9b à¤\\x95à¤°à¤¨à¤¾ à¤¹à¥\\x88 à¤\\x95à¥\\x81à¤\\x9b à¤®à¤°à¤®à¥\\x8dà¤®à¤¤ à¤\\x95à¥\\x87 à¤¸à¤¾à¤¥à¥¤ à¤²à¥\\x87à¤\\x95à¤¿à¤¨ à¤\\x8fà¤\\x95 à¤«à¤¿à¤\\x95à¥\\x8dà¤¸ à¤®à¥\\x87à¤\\x82 à¤\\x95à¥\\x8bà¤\\x88 à¤\\xadà¥\\x80 à¤ªà¤°à¥\\x87à¤¶à¤¾à¤¨à¥\\x80 à¤\\x95à¤¾ à¤®à¤¤à¤²à¤¬ à¤¨à¤¹à¥\\x80à¤\\x82 à¤¹à¥\\x88 à¤\\x8fà¤\\x95 à¤ªà¤°à¥\\x87à¤¶à¤¾à¤¨à¥\\x80 à¤\\x95à¥\\x80 à¤¸à¥\\x8dà¤¥à¤¿à¤¤à¤¿ à¤®à¥\\x87à¤\\x82 à¤¦à¥\\x82à¤¸à¤°à¥\\x87 à¤¶à¤¬à¥\\x8dà¤¦à¥\\x8bà¤\\x82 à¤\\x95à¤¾ à¤\\x89à¤ªà¤¯à¥\\x8bà¤\\x97 à¤\\x95à¤°à¥\\x87à¤\\x82 à¤\\x9cà¤¿à¤¨à¥\\x8dà¤¹à¥\\x87à¤\\x82 à¤\\x86à¤ª à¤\\x8fà¤\\x95 à¤«à¤¿à¤\\x95à¥\\x8dà¤¸ à¤®à¥\\x87à¤\\x82 à¤\\x89à¤ªà¤¯à¥\\x8bà¤\\x97 à¤\\x95à¤° à¤¸à¤\\x95à¤¤à¥\\x87 à¤¹à¥\\x88à¤\\x82 à¤®à¥\\x88à¤\\x82 à¤\\x8fà¤\\x95 à¤¸à¥\\x82à¤ª à¤®à¥\\x87à¤\\x82 à¤¹à¥\\x82à¤\\x82 à¤¯à¤¾ à¤®à¥\\x88à¤\\x82 ' à¤\\x8fà¤\\x95 à¤\\x97à¤¡à¤¼à¤¬à¤¡à¤¼ à¤®à¥\\x87à¤\\x82 à¤¹à¥\\x82à¤\\x81 à¤¯à¤¾ à¤®à¥\\x88à¤\\x82 à¤ªà¤°à¥\\x87à¤¶à¤¾à¤¨ à¤\\x95à¥\\x87 à¤\\x8fà¤\\x95 à¤¸à¥\\x8dà¤¥à¤¾à¤¨ à¤ªà¤° à¤¹à¥\\x82à¤\\x81 à¤¯à¤¾ à¤¬à¤¸ à¤®à¥\\x88à¤\\x82 à¤\\x8fà¤\\x95 à¤¸à¥\\x8dà¤ªà¥\\x89à¤\\x9f à¤®à¥\\x87à¤\\x82 à¤¹à¥\\x82à¤\\x81 à¤¸à¥\\x8dà¤®à¤¾à¤°à¥\\x8dà¤\\x9f à¤¶à¤¬à¥\\x8dà¤¦ à¤¸à¤\\x82à¤\\x96à¥\\x8dà¤¯à¤¾ 7 à¤¹à¥\\x88 à¤«à¥\\x8dà¤²à¥\\x81à¤®à¥\\x89à¤\\x95à¥\\x8dà¤¸ à¤«à¥\\x8dà¤²à¥\\x81à¤®à¥\\x8bà¤\\x95à¥\\x8dà¤¸ à¤\\x95à¤¾ à¤®à¤¤à¤²à¤¬ à¤\\x95à¤¿à¤¸à¥\\x80 à¤\\x95à¥\\x8b à¤\\xadà¥\\x8dà¤°à¤®à¤¿à¤¤ à¤\\x95à¤°à¤¨à¤¾ à¤¹à¥\\x88à¥¤ à¤\\x87à¤¤à¤¨à¤¾ à¤¹à¥\\x88 à¤\\x95à¤¿ à¤µà¥\\x87 à¤\\xadà¥\\x82à¤² à¤\\x9cà¤¾à¤¤à¥\\x87 à¤¹à¥\\x88à¤\\x82 à¤\\x95à¤¿ à¤\\x85à¤¬ à¤\\x95à¥\\x8dà¤¯à¤¾ à¤\\x95à¤°à¤¨à¤¾ à¤¹à¥\\x88 à¤\\x89à¤²à¤\\x9dà¤¨ à¤®à¥\\x87à¤\\x82 à¤\\x8fà¤\\x95 à¤\\x85à¤¤à¤¿ à¤ªà¥\\x8dà¤°à¤¯à¥\\x8bà¤\\x97 à¤¶à¤¬à¥\\x8dà¤¦ à¤¹à¥\\x8b à¤\\x9cà¤¾à¤¤à¤¾ à¤¹à¥\\x88 à¤¤à¥\\x8b à¤\\x87à¤¸à¤\\x95à¥\\x87 à¤¬à¤\\x9cà¤¾à¤¯ à¤\\x86à¤ª à¤\\x89à¤¦à¤¾à¤¹à¤°à¤£ à¤\\x95à¥\\x87 à¤²à¤¿à¤\\x8f flummox à¤\\x95à¤¾ à¤\\x89à¤ªà¤¯à¥\\x8bà¤\\x97 à¤\\x95à¥\\x8dà¤¯à¥\\x8bà¤\\x82 à¤¨à¤¹à¥\\x80à¤\\x82 à¤\\x95à¤°à¤¤à¥\\x87 à¤¹à¥\\x88à¤\\x82à¥¤ à¤²à¤¡à¤¼à¤\\x95à¤¾ à¤ªà¥\\x82à¤°à¥\\x80 à¤¤à¤°à¤¹ à¤¸à¥\\x87 à¤¦à¤¿à¤\\x96à¤¤à¤¾ à¤¹à¥\\x88 à¥¤flummoxed à¤\\x9cà¤¬ à¤¶à¤¿à¤\\x95à¥\\x8dà¤·à¤\\x95 à¤¨à¥\\x87 à¤\\x89à¤¸à¥\\x87 à¤\\x95à¤\\x95à¥\\x8dà¤·à¤¾ à¤®à¥\\x87à¤\\x82 à¤\\x8fà¤\\x95 à¤¸à¤µà¤¾à¤² à¤ªà¥\\x82à¤\\x9bà¤¾ à¤¯à¤¾ à¤\\x95à¥\\x81à¤¤à¥\\x8dà¤¤à¥\\x87 à¤\\x95à¥\\x8b à¤¦à¥\\x87à¤\\x96 à¤¶à¤°à¤¾à¤¬à¥\\x80 à¤¹à¥\\x8b à¤\\x97à¤¯à¤¾à¥¤ à¤¦à¤°à¥\\x8dà¤ªà¤£ à¤®à¥\\x87à¤\\x82 à¤\\x85à¤ªà¤¨à¥\\x87 à¤¸à¥\\x8dà¤µà¤¯à¤\\x82 à¤\\x95à¥\\x87 à¤ªà¥\\x8dà¤°à¤¤à¤¿à¤¬à¤¿à¤\\x82à¤¬ à¤¯à¤¾ à¤ªà¤°à¥\\x8dà¤¯à¤\\x9fà¤\\x95 à¤\\x95à¥\\x8b à¤\\x85à¤²à¤\\x97-à¤\\x85à¤²à¤\\x97 à¤°à¥\\x80à¤¤à¤¿-à¤°à¤¿à¤µà¤¾à¤\\x9cà¥\\x8bà¤\\x82 à¤¸à¥\\x87 à¤²à¤¾à¤¦ à¤¦à¤¿à¤¯à¤¾ à¤\\x97à¤¯à¤¾ à¤¥à¤¾à¥¤ à¤\\x85à¤ªà¤¨à¥\\x80 à¤¯à¤¾à¤¤à¥\\x8dà¤°à¤¾ à¤\\x95à¥\\x87 à¤¦à¥\\x8cà¤°à¤¾à¤¨ à¤¯à¤¾ à¤\\x8fà¤\\x95 à¤¸à¤¾à¤\\x95à¥\\x8dà¤·à¤¾à¤¤à¥\\x8dà¤\\x95à¤¾à¤° à¤\\x95à¥\\x87 à¤¦à¥\\x8cà¤°à¤¾à¤¨ à¤\\x89à¤¨à¤\\x95à¤¾ à¤¸à¤¾à¤®à¤¨à¤¾ à¤¹à¥\\x81à¤\\x86\"\n",
      " 'Tamil' 'Portugeese' 'French' 'Dutch' 'Spanish' 'Greek' 'Russian'\n",
      " 'Danish' 'Italian' 'Turkish' 'Sweedish' 'Arabic' 'German' 'Kannada']\n"
     ]
    }
   ],
   "source": [
    "all_languages = df[\"Language\"].unique() # gets all unique values in the \"Language\" column of the dataframe\n",
    "print(all_languages) # prints all the languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "id": "1b135a12-9437-4c5e-9455-a564dc7e54a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the DataFrame\n",
    "languages_to_keep = ['English', 'German', 'French', 'Spanish'] # specifies the languages that will be kept\n",
    "df = df[df['Language'].isin(languages_to_keep)] # performs the filtering operation\n",
    "\n",
    "\n",
    "df.reset_index(drop=True, inplace=True) # resets the index after filtering to ensure a clean, sequential index.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "id": "4f447c45-f134-4c73-9f56-f8bb7a91d9ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nature, in the broadest sense, is the natural...</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"Nature\" can refer to the phenomena of the phy...</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The study of nature is a large, if not the onl...</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Although humans are part of nature, human acti...</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[1] The word nature is borrowed from the Old F...</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6683</th>\n",
       "      <td>notices dans des bases relatives au sport  ass...</td>\n",
       "      <td>French</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6684</th>\n",
       "      <td>el investigador ha recibido varios reconocimie...</td>\n",
       "      <td>Spanish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6685</th>\n",
       "      <td>le village est une station familiale de sports...</td>\n",
       "      <td>French</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6686</th>\n",
       "      <td>hors du terrain les annÃ©es  et  sont des annÃ...</td>\n",
       "      <td>French</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6687</th>\n",
       "      <td>con motivo de la celebraciÃ³n del septuagÃ©sim...</td>\n",
       "      <td>Spanish</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6688 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Text Language\n",
       "0      Nature, in the broadest sense, is the natural...  English\n",
       "1     \"Nature\" can refer to the phenomena of the phy...  English\n",
       "2     The study of nature is a large, if not the onl...  English\n",
       "3     Although humans are part of nature, human acti...  English\n",
       "4     [1] The word nature is borrowed from the Old F...  English\n",
       "...                                                 ...      ...\n",
       "6683  notices dans des bases relatives au sport  ass...   French\n",
       "6684  el investigador ha recibido varios reconocimie...  Spanish\n",
       "6685  le village est une station familiale de sports...   French\n",
       "6686  hors du terrain les annÃ©es  et  sont des annÃ...   French\n",
       "6687  con motivo de la celebraciÃ³n del septuagÃ©sim...  Spanish\n",
       "\n",
       "[6688 rows x 2 columns]"
      ]
     },
     "execution_count": 420,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df # displays the cleaned DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ea9ef9-f3fa-4ccb-a997-1a8a1b43651c",
   "metadata": {},
   "source": [
    "### Checking for Outliers in Categorical Data\n",
    "\n",
    "In the context of **categorical data**, traditional outlier detection methods are not applicable, as these techniques are designed for **numerical** values that possess a defined range. Instead in this scenario, outliers in categorical data would be considered as invalid characters. Addressing these invalid entries is crucial for ensuring data integrity, enhancing model performance, and maintaining consistency across datasets. This process not only improves readability and comprehension for users by removing distractions and errors but also contributes to more accurate analyses and predictions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "id": "a485e7ce-71d4-47e7-ab77-5e84c07cc1ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_13216\\1179762154.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Language'] = df['Language'].str.replace(r'[^a-zA-Zа-яА-ЯёЁ一-龯]', '', regex=True) # uses regex to removes invalid characters, keeping only valid letters from any language\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df['Language'] = df['Language'].str.replace(r'[^a-zA-Zа-яА-ЯёЁ一-龯]', '', regex=True) # uses regex to removes invalid characters, keeping only valid letters from any language\n",
    "\n",
    "\n",
    "df.reset_index(drop=True, inplace=True) # resets the index after cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "id": "89efeaef-72f5-4eb1-8909-cd40ff72e642",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nature, in the broadest sense, is the natural...</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"Nature\" can refer to the phenomena of the phy...</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The study of nature is a large, if not the onl...</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Although humans are part of nature, human acti...</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[1] The word nature is borrowed from the Old F...</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6683</th>\n",
       "      <td>notices dans des bases relatives au sport  ass...</td>\n",
       "      <td>French</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6684</th>\n",
       "      <td>el investigador ha recibido varios reconocimie...</td>\n",
       "      <td>Spanish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6685</th>\n",
       "      <td>le village est une station familiale de sports...</td>\n",
       "      <td>French</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6686</th>\n",
       "      <td>hors du terrain les annÃ©es  et  sont des annÃ...</td>\n",
       "      <td>French</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6687</th>\n",
       "      <td>con motivo de la celebraciÃ³n del septuagÃ©sim...</td>\n",
       "      <td>Spanish</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6688 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Text Language\n",
       "0      Nature, in the broadest sense, is the natural...  English\n",
       "1     \"Nature\" can refer to the phenomena of the phy...  English\n",
       "2     The study of nature is a large, if not the onl...  English\n",
       "3     Although humans are part of nature, human acti...  English\n",
       "4     [1] The word nature is borrowed from the Old F...  English\n",
       "...                                                 ...      ...\n",
       "6683  notices dans des bases relatives au sport  ass...   French\n",
       "6684  el investigador ha recibido varios reconocimie...  Spanish\n",
       "6685  le village est une station familiale de sports...   French\n",
       "6686  hors du terrain les annÃ©es  et  sont des annÃ...   French\n",
       "6687  con motivo de la celebraciÃ³n del septuagÃ©sim...  Spanish\n",
       "\n",
       "[6688 rows x 2 columns]"
      ]
     },
     "execution_count": 423,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df # displays the modified dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea94782-ab37-4d0b-9e02-c70ab1945453",
   "metadata": {},
   "source": [
    "### Language Distribution Check\n",
    "\n",
    "The Language Distribution Check assesses the number of entries for each language  be detected to ensure they are approximately equal. This is important because imbalanced data can skew the results of language detection model, leading to biased outcomes. By verifying the distribution, we can enhance the model's performance and ensure it is trained on a representative sample of each language, ultimately improving accuracy and reliability in language identification.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "id": "d699d117-b0fe-4243-a0d6-2bfce8fdcfdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Language\n",
       "English    2385\n",
       "French     2014\n",
       "Spanish    1819\n",
       "German      470\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 425,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Language'].value_counts() # displays the number of entries for each of the four languages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7591989b-b7c1-45b3-a5f6-7f0a5b7a2d64",
   "metadata": {},
   "source": [
    "##### Observation:\n",
    "\n",
    "The analysis of the language distribution check revealed that the four languages did not have an equal number of entries. To address this imbalance, online sources will be sourcesd to gather additional data and ensure a more uniform representation of each language.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a4e9d5-b808-4fc3-99d7-8dada8c0a071",
   "metadata": {},
   "source": [
    "### Saving the Cleaned Dataframe \n",
    "After the cleaning process, the dataframe is saved to a CSV file for proper assessment before further structuring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "id": "d0dd7bf0-db49-44bb-8e46-fc192f6c1298",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"Cleaned_Data.csv\", index = False) # saves the dataframe to a csv whithout adding an index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae9cbdcf-3a3c-41b6-8821-8b105b6135f4",
   "metadata": {},
   "source": [
    "### Data Encoding\n",
    "For the \"Language\" column, **Label Encoding** will be used to convert categorical language values into numeric labels, enabling the machine learning model to interpret them. For the \"Text\" column, **TF-IDF Vectorization** with character n-grams (specifically three-grams to five-grams) will be applied to transform the text into a numerical format. This approach captures important character sequences, highlighting their significance within the dataset and providing a more nuanced representation of the text compared to traditional encoding techniques.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a65959-6222-4fa6-bb3e-43e916462af3",
   "metadata": {},
   "source": [
    "#### Label Encoding for the `Language` Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "id": "57dbdb3b-254f-4288-8f6b-d86ffe6ae608",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_13216\\4249261989.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Language'] = encoder.fit_transform(df['Language']) # uses the Label encoding object to encode the \"Language\" column in the dataframe\n"
     ]
    }
   ],
   "source": [
    "encoder = LabelEncoder() # initializes the label encoder\n",
    "\n",
    "df['Language'] = encoder.fit_transform(df['Language']) # uses the Label encoding object to encode the \"Language\" column in the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "id": "0dc6a264-5fd9-42c9-b150-113a3be0cc20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping of Language to Label: {'English': 0, 'French': 1, 'German': 2, 'Spanish': 3}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "mapping = dict(zip(encoder.classes_, encoder.transform(encoder.classes_))) # computes the numeric labels for each mapped language using a dictionary\n",
    "print(\"Mapping of Language to Label:\", mapping) # displays the dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "416ef39f-f893-4568-af37-0e9d22213195",
   "metadata": {},
   "source": [
    "#### Vectorization for the `Text` Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "id": "647ec637-0d30-40d9-9fee-84767b7fac6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = df['Text'] # gets the Text column of the dataframe that contains the sentences to be vectorized \n",
    "\n",
    "# the TF-IDF vectorizer with character-level n-grams\n",
    "tfidf_char_vectorizer = TfidfVectorizer(analyzer='char', ngram_range=(3, 5))  # initializes the vectorizer with character three grams to 5-grams\n",
    "X = tfidf_char_vectorizer.fit_transform(texts)  # vectorizes the text which will serve as the independent variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "id": "45a984d7-dc5a-4f81-bfba-f73ed743a826",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 96690)\t0.0953924399709766\n",
      "  (0, 249878)\t0.06373029569451795\n",
      "  (0, 133296)\t0.047716214931696824\n",
      "  (0, 167733)\t0.05074564129315794\n",
      "  (0, 243813)\t0.0512582772015565\n",
      "  (0, 19595)\t0.0526483475349929\n",
      "  (0, 197333)\t0.07666670557773968\n",
      "  (0, 183729)\t0.06388440328461689\n",
      "  (0, 14955)\t0.08520640239933906\n",
      "  (0, 73487)\t0.07534813165587641\n",
      "  (0, 143092)\t0.10133587207109072\n",
      "  (0, 205117)\t0.0932711372352149\n",
      "  (0, 184405)\t0.06229205313240643\n",
      "  (0, 254029)\t0.058513297361448446\n",
      "  (0, 20673)\t0.05891111228172097\n",
      "  (0, 140665)\t0.08185923502071019\n",
      "  (0, 47522)\t0.08048883494209211\n",
      "  (0, 120923)\t0.08261013767785381\n",
      "  (0, 203568)\t0.06229205313240643\n",
      "  (0, 96084)\t0.06883702829104263\n",
      "  (0, 230268)\t0.0683715681049111\n",
      "  (0, 55366)\t0.07149280696813971\n",
      "  (0, 153416)\t0.06957211183908206\n",
      "  (0, 12996)\t0.06749304128382207\n",
      "  (0, 26909)\t0.09798870469246183\n",
      "  :\t:\n",
      "  (6687, 16372)\t0.0093630388452366\n",
      "  (6687, 160447)\t0.016491498398866693\n",
      "  (6687, 49493)\t0.011361076810703055\n",
      "  (6687, 5175)\t0.011096081763998263\n",
      "  (6687, 133296)\t0.019719391116472255\n",
      "  (6687, 167733)\t0.020971343798924447\n",
      "  (6687, 249872)\t0.01628379838528637\n",
      "  (6687, 133283)\t0.018598762445754903\n",
      "  (6687, 167730)\t0.020084334287668714\n",
      "  (6687, 219162)\t0.024783258729522268\n",
      "  (6687, 96618)\t0.012048285427882792\n",
      "  (6687, 249735)\t0.012120101252843735\n",
      "  (6687, 133223)\t0.013545205189150743\n",
      "  (6687, 167729)\t0.020032908059151644\n",
      "  (6687, 183487)\t0.010977935610538909\n",
      "  (6687, 120897)\t0.01562710134826581\n",
      "  (6687, 230160)\t0.010686128740213158\n",
      "  (6687, 64840)\t0.015466138819260497\n",
      "  (6687, 121794)\t0.012362928494184137\n",
      "  (6687, 219134)\t0.020206511988794633\n",
      "  (6687, 217809)\t0.01518434649277021\n",
      "  (6687, 17327)\t0.019712962386047285\n",
      "  (6687, 98280)\t0.019433613634162315\n",
      "  (6687, 76973)\t0.01134985555349455\n",
      "  (6687, 10538)\t0.008987017479305427\n"
     ]
    }
   ],
   "source": [
    "print(X) # prints the sparse matrix of TF-IDF scores for the text data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "412474f4-4495-4319-b47a-54372ad606c7",
   "metadata": {},
   "source": [
    "##### Observation\n",
    "The output represents a sparse matrix of TF-IDF scores for  the each sentence in the dataset. Each entry follows the format `(row_index, column_index) value`. Here, `0` indicates the row index (the first sentence), `54921`indicates the position of a specific character n-gram in the vectorizer's vocabulary. Each unique n-gram detected across all sentences gets a unique index. So, 54921 corresponds to a particular n-gram (like a trigram or five-gram) that was identified during the vectorization process. The value (e.g., `0.0953924399709766` represents the TF-IDF score for that n-gram. This score reflects the importance of that particular character sequence within the context of the first sentence, with higher values indicating greater significance. This structure allows for efficient storage and processing, especially in large datasets with many zero entries.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7daca30e-4c89-492e-83bd-3e795a5c570c",
   "metadata": {},
   "source": [
    "### Feature Relationships\r\n",
    "In this context, using a correlation matrix to analyze feature relationships is not particularly important. The high dimensionality of TF-IDF features, derived from n-grams, results in a sparse matrix where many features have zero values for most documents. This makes correlation analysis less interpretable. Additionally, the nature of these features—representing textual information rather than numerical values—renders traditional correlation metrics less meaningful. Therefore, while correlation matrices are useful for many datasets, they may not provide valuable insights in the case of TF-IDF representations.\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22276921-be60-42fd-870d-bd2dd2f0b1f6",
   "metadata": {},
   "source": [
    "### Feature and Target Definition\n",
    "In this analysis, the **features** (or predictors) represent the independent variables used to predict the **target** variable. The **features** consist of the `Text` column, which contains sentences in various languages. This feature captures the textual characteristics that will be analyzed.\n",
    "\n",
    "The **target variable** is the dependent variable, which is the `Language` column, representing the language corresponding to each sentence. The goal of the analysis is to understand how the textual features influence the target, specifically how each feature contributes to predicting the language of the text `Y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "id": "5dc01ece-a06a-4bd8-9c78-ff2c21e95b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X # the text that was vectorized earlier\n",
    "Y = df['Language'] # the label encoded column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "id": "b29cfe12-2a8b-457a-8bf9-68b431cacb5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6688, 284850) (6688,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape, Y.shape) # displays the shape of the independent and dependent variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d03dc314-bb11-4e32-a11d-4c1343926319",
   "metadata": {},
   "source": [
    "### Train-Test Split\n",
    "To split the dataset into training and testing sets, the **train_test_split** function from sklearn will be used, applying an 80-20 ratio. The following steps are taken:\n",
    "\n",
    "1. **X_train and Y_train**: The feature columns from the dataset are extracted to create the training feature set (X_train), while the corresponding target variable (the `Language` column) is extracted to form the training target set (Y_train). This enables the model to learn from the features and their associated labels.\n",
    "\n",
    "2. **X_test and Y_test**: The remaining data is used to create the testing feature set (X_test) and the testing target set (Y_test). This allows the model to evaluate its performance on unseen data, providing insights into its predictive capability.\n",
    "\n",
    "The following line of code splits the dataset into training and testing sets:\n",
    "\n",
    "```X_train, X_test, texts_train, texts_test, Y_train, Y_test = train_test_split( X, texts, Y, test_size=0.2, random_state=42, stratify=Y)```.\r",
    "\r\n",
    "\r\n",
    "### Reason for Splitting Both Vectorized and Original Text\r\n",
    "- By splitting both the vectorized features (`X`) and the original text (`texts`), we can easily visualize the exact text that the model used to predict a language after testing.\r\n",
    "- The original text provides a human-readable format, while the vectorized and encoded forms would be difficult to interpret.\r\n",
    "- This allows for a clearer understanding of how the model performs in terms of predicting languages based on actual text input, making the evaluation more meaningful.\r\n",
    "\r\n",
    "### Parameters\r\n",
    "- **`X`**: Represents the feature matrix (vectorized representations of the text).\r\n",
    "- **`texts`**: Contains the original text data for visualization.\r\n",
    "- **`Y`**: Represents the target labels (encoded languages).\r\n",
    "- **`test_size=0.2`**: Allocates 20% of the dataset for testing, ensuring that the model is evaluated on unseen data.\r\n",
    "- **`random_state=42`**: Ensures the split is reproducible by setting a seed for random number generation.\r\n",
    "- **`stratify=Y`**: Maintains the same proportion of target classes in both the training and testing sets, helping to avoid class imbalance issues.\r\n",
    "\r\n",
    "This approach enhances the ability to assess the model's predictions in a way that is understandable to humans, as it links the original text directly to the model's output.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "id": "60d15113-6c88-4b5f-8793-e5ed66b86e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42) # splits data into 80% training and 20% testing sets for model training and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "id": "c4ced712-2f00-4ac7-8863-3e512b966074",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, texts_train, texts_test, Y_train, Y_test = train_test_split( X, texts, Y, test_size=0.2, random_state=42, stratify=Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73307fa8-72b4-4444-961e-ce2048d3498d",
   "metadata": {},
   "source": [
    "### Feature Scaling\r\n",
    "In this analysis, there is no need for feature scaling because the model is based on textual data represented by TF-IDF vectors. Since TF-IDF inherently normalizes the values to reflect the importance of terms, all features are already on a comparable scale, eliminating the necessity for additional scaling.\r\n",
    "\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf6dfd0-307f-4f9c-ba4e-29963d803572",
   "metadata": {},
   "source": [
    "### Classification Analysis\n",
    "\n",
    "The next step involves performing **Classification Analysis** using **Multinomial Naive Bayes** (MNB). This technique is commonly used for text classification tasks where the features represent word counts or term frequencies (e.g., TF-IDF). MNB assumes that the features follow a multinomial distribution, making it ideal for language detection where the data is represented by discrete counts, such as text in the `Text` column of the dataframe `df`.\n",
    "\n",
    "The probability of a class \\( C \\) given a document \\( d \\) is calculated using **Bayes' Theorem**:\n",
    "\n",
    "   - **Formula**:\n",
    "     $$\n",
    "     P(C|d) = \\frac{P(C) \\prod_{i=1}^{n} P(w_i|C)}{P(d)}\n",
    "     $$\n",
    "   - **Where**:\n",
    "     - $P(C|d)$ = posterior probability of class \\( C \\) given document \\( d \\)\n",
    "     - $( P(C)$ = prior probability of class \\( C \\)\n",
    "     - $P(w_i|C)$ = likelihood of word \\( w_i \\) given class \\( C \\)\n",
    "     - $P(d)$ = probability of the document (acts as a normalizing constant)\n",
    "     - $n$ = total number of words or features in the document\n",
    "\n",
    "\n",
    "MNB works by learning the conditional probabilities of each feature (word or character n-gram) given each class. The model assigns the class that maximizes the posterior probability, given the input text. This makes it effective for **language detection** and other text classification tasks where text features play a critical role.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "id": "35123362-f70b-456a-ad50-a281f108b8ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-5 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-5 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-5 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-5 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-5 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-5 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-5 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-5 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-5 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-5 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-5 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-5 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB(alpha=0.1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;MultinomialNB<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.naive_bayes.MultinomialNB.html\">?<span>Documentation for MultinomialNB</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>MultinomialNB(alpha=0.1)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "MultinomialNB(alpha=0.1)"
      ]
     },
     "execution_count": 446,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MultinomialNB(alpha= 0.1, fit_prior = True) # initializes the multimodal Naive Bayes Model\n",
    "model.fit(X_train, Y_train) # performs the training process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ef6ea0-aee9-460b-97be-8a564370d1b4",
   "metadata": {},
   "source": [
    "#### Detections "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "id": "e0244b77-66d4-449c-acfc-5ef07fb8b867",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_detect = model.predict(X_test) # make detections / predictions on the test data (i.e unseen data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6961fc8-5f5c-4e7f-a819-1e6fe8efae59",
   "metadata": {},
   "source": [
    "#### Results\n",
    "A DataFrame will be created to display the detected languages alongside their corresponding text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "id": "20fb435d-0fd6-44ea-ac02-15856e4f4f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uses the mapping dictionary earlier defined under the Label encoding section to get the all keys of the dictionary (i.e the languages)\n",
    "languages = list(mapping.keys())  # ['English', 'French', 'German', 'Spanish'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "id": "66ad2a66-2784-4903-9574-8706f7fc0a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder() # initializes the label encoder\n",
    "label_encoder.fit(languages) # fits the label encoder with the language names -- ['English', 'French', 'German', 'Spanish'] \n",
    "Y_detect_lang = label_encoder.inverse_transform(Y_detect) # uses inverse_transform to convert encoded predictions back to language names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "id": "284d627c-0287-4f8b-b791-eb98399726cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = pd.DataFrame({\n",
    "    'Text': texts_test,       # Original text from the test set\n",
    "    'Predicted_Language': Y_detect_lang  # Predicted languages after decoding\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "id": "0774a68b-39a2-4800-a38f-675fa816cf52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Predicted_Language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>550</th>\n",
       "      <td>[218][note 6] It is a battle between the right...</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6025</th>\n",
       "      <td>la situaciÃ³n causÃ³ que himmler ordene desarm...</td>\n",
       "      <td>Spanish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4215</th>\n",
       "      <td>le championnat - qui se dÃ©roula pendant le pa...</td>\n",
       "      <td>French</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3737</th>\n",
       "      <td>la economÃ­a es fundamentalmente agrÃ­cola con...</td>\n",
       "      <td>Spanish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2625</th>\n",
       "      <td>Wikipedia actualmente se ejecuta en grupos ded...</td>\n",
       "      <td>Spanish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1993</th>\n",
       "      <td>Ces programmes, selon leur degrÃ© de perfectio...</td>\n",
       "      <td>French</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1532</th>\n",
       "      <td>Depuis peu, et au niveau international, ils te...</td>\n",
       "      <td>French</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>Katherine Maher, the nonprofit Wikimedia Found...</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3845</th>\n",
       "      <td>within two years of forming a live band stick ...</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5600</th>\n",
       "      <td>Ã©ric de beukelaer est titulaire de licences e...</td>\n",
       "      <td>French</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1338 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Text Predicted_Language\n",
       "550   [218][note 6] It is a battle between the right...            English\n",
       "6025  la situaciÃ³n causÃ³ que himmler ordene desarm...            Spanish\n",
       "4215  le championnat - qui se dÃ©roula pendant le pa...             French\n",
       "3737  la economÃ­a es fundamentalmente agrÃ­cola con...            Spanish\n",
       "2625  Wikipedia actualmente se ejecuta en grupos ded...            Spanish\n",
       "...                                                 ...                ...\n",
       "1993  Ces programmes, selon leur degrÃ© de perfectio...             French\n",
       "1532  Depuis peu, et au niveau international, ils te...             French\n",
       "473   Katherine Maher, the nonprofit Wikimedia Found...            English\n",
       "3845  within two years of forming a live band stick ...            English\n",
       "5600  Ã©ric de beukelaer est titulaire de licences e...             French\n",
       "\n",
       "[1338 rows x 2 columns]"
      ]
     },
     "execution_count": 453,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results # displays the dataframe containing the results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb76ac0e-c4f0-493e-a518-14ae0bae5ab7",
   "metadata": {},
   "source": [
    "### Model Evaluation Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d83fd85-b9e8-4733-ba08-b232bf35f883",
   "metadata": {},
   "source": [
    "\n",
    "#### 1. **Accuracy**\n",
    "- **Definition**: Accuracy measures the ratio of correctly predicted instances to the total number of instances. It is useful for determining the overall effectiveness of the model.\n",
    "- **Formula**:\n",
    "  $$\n",
    "  \\text{Accuracy} = \\frac{\\text{TP + TN}}{\\text{TP + TN + FP + FN}}\n",
    "  $$\n",
    "  - **Where**:\n",
    "    - **TP** = True Positives, **TN** = True Negatives\n",
    "    - **FP** = False Positives, **FN** = False Negatives\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "id": "e30eac5b-6278-4d7d-a45e-6090f8563b2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9955156950672646\n"
     ]
    }
   ],
   "source": [
    "accuracy = model.score(X_test, Y_test) # computes and displays the accuracy\n",
    "print(f\"Accuracy: {accuracy}\") # displays the accuracy\n",
    "\n",
    "# OR\n",
    "# y_pred = model.predict(X_test)\n",
    "# accuracy = accuracy_score(Y_test, Y_detect)\n",
    "# print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee2b1861-f297-45f1-9d61-27cb58132c5a",
   "metadata": {},
   "source": [
    "\n",
    "#### 2. **Precision**\n",
    "- **Definition**: Precision calculates the proportion of correctly predicted positive instances out of all predicted positives. It is useful when minimizing false positives is important.\n",
    "- **Formula**:\n",
    "  $$\n",
    "  \\text{Precision} = \\frac{\\text{TP}}{\\text{TP + FP}}\n",
    "  $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "id": "c271630c-f885-4feb-bba8-7fb223105155",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.9955211387988847\n"
     ]
    }
   ],
   "source": [
    "precision = precision_score(Y_test, Y_detect, average='weighted') # computes the precision\n",
    "# precision = precision_score(Y_test, Y_detect, average='macro') # optionally, use this when you have balanced classes in the language division\n",
    "print(f\"Precision: {precision}\") # displays the precision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8720fcde-32f9-416b-b978-7f2d53b9f751",
   "metadata": {},
   "source": [
    "#### 3. **Recall (Sensitivity or True Positive Rate)**\n",
    "- **Definition**: Recall measures the proportion of correctly predicted positive instances out of all actual positives. It is crucial when missing positive instances (false negatives) is costly.\n",
    "- **Formula**:\n",
    "  $$\n",
    "  \\text{Recall} = \\frac{\\text{TP}}{\\text{TP + FN}}\n",
    "  $$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "id": "154afde9-dbb7-4b12-b5b8-1dd0270e6059",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall:0.9955156950672646\n"
     ]
    }
   ],
   "source": [
    "recall = recall_score(Y_test, Y_detect, average = 'weighted') # computes the recall\n",
    "# recall = recall_score(Y_test, Y_detect, average = 'macro') # optionally use this when you have balanced classes in the language division\n",
    "print(f\"Recall:{recall}\") # displays the recall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ff044b-ceb5-4a35-a28a-b871fea1a42d",
   "metadata": {},
   "source": [
    "#### 4. **F1-Score**\n",
    "- **Definition**: The F1-Score is the harmonic mean of precision and recall. It balances the two metrics and is useful when both false positives and false negatives are important.\n",
    "- **Formula**:\n",
    "  $$\n",
    "  \\text{F1-Score} = 2 \\cdot \\frac{\\text{Precision} \\cdot \\text{Recall}}{\\text{Precision} + \\text{Recall}}\n",
    "  $$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "id": "ba707676-2be9-4077-8d05-675f880f879e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.9955158874982464\n"
     ]
    }
   ],
   "source": [
    "f1 = f1_score(Y_test, Y_detect, average= \"weighted\") # computes the f1-score\n",
    "# f1 = f1_score(Y_test, Y_detect, average= \"macro\") # optionally use this when you have balanced classes in the language division\n",
    "print(f\"F1-Score: {f1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd8af13b-b0e7-4ea0-bd0f-0b0bfd05cea4",
   "metadata": {},
   "source": [
    "#### 5. **Confusion Matrix**\n",
    "- **Definition**: A confusion matrix is a table that shows the actual versus predicted classifications, providing a detailed breakdown of correct and incorrect predictions for all classes.\n",
    "- **Example Matrix**:\n",
    "  |        | Predicted Positive | Predicted Negative |\n",
    "  |--------|--------------------|--------------------|\n",
    "  | Actual Positive | TP                 | FN                 |\n",
    "  | Actual Negative | FP                 | TN                 |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "id": "18181fd7-d61f-4cb6-803c-17240fda9277",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "conf_matrix = confusion_matrix(Y_test, Y_detect) # computes the confusion matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "id": "b31e7d4a-293c-460d-b054-e882bfc1a3f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>English</th>\n",
       "      <th>French</th>\n",
       "      <th>German</th>\n",
       "      <th>Spanish</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>English</th>\n",
       "      <td>476</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>French</th>\n",
       "      <td>1</td>\n",
       "      <td>401</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>German</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>93</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Spanish</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>362</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         English  French  German  Spanish\n",
       "English      476       1       0        0\n",
       "French         1     401       0        1\n",
       "German         1       0      93        0\n",
       "Spanish        1       0       1      362"
      ]
     },
     "execution_count": 465,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the mapping to reverse for labeling\n",
    "mapping = {v: k for k, v in mapping.items()} # uses dictionary comprehension to swap key-value pairs in the mapping variable earlier define under Label encoding\n",
    "\n",
    "# converts the confusion matrix array to a dataFrame for better readability\n",
    "confusion_mtrx_df = pd.DataFrame(conf_matrix, # the array to be converted to a dataframe\n",
    "                            index=[mapping[i] for i in range(len(mapping))], # acceses each value in the modified mapping dictionary by their corresponding keys and using it to label the rows of the dataframe\n",
    "                            columns=[mapping[i] for i in range(len(mapping))] # acceses each value in the modified mapping dictionary by their corresponding keys and using it to label the columns of the dataframe\n",
    "                           )\n",
    "\n",
    "confusion_mtrx_df # displays the confusion matrix dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00fc834d-262b-4708-a569-af6003994978",
   "metadata": {},
   "source": [
    "##### Observation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fccfe67c-0a6c-4efd-94f6-dd88d1e3d274",
   "metadata": {},
   "source": [
    "The confusion matrix above describes the True positives and False Positives for each of the Languages the model tried to detect.\n",
    "\n",
    "1. **First row (True Class = English (0))**:\n",
    "   - **478** English instances were predicted correctly as English.\n",
    "   - **0** English instances were incorrectly predicted as French, Spanish, or German.\n",
    "\n",
    "2. **Second row (True Class = French (1))**:\n",
    "   - **410** French instances were predicted correctly as French.\n",
    "   - **0** French instances were incorrectly predicted as English, Spanish, or German.\n",
    "\n",
    "3. **Third row (True Class = German (2))**:\n",
    "   - **81** German instances were predicted correctly as German.\n",
    "   - **1** German instances were incorrectly predicted as English.\n",
    "   - **0** German instances were incorrectly predicted as French and Spanish.\n",
    "\n",
    "4. **Fourth row (True Class = Spanish (3))**:\n",
    "   - **364** Spanish instances were predicted correctly as Spanish.\n",
    "   - **3** Spanish instances were incorrectly predicted as English.\n",
    "   - **1** Spanish instance was incorrectly predicted as French.\n",
    "   - **0** Spanish instances were incorrectly predicted as German.\n",
    "\n",
    "**In Summary**:\n",
    "- For each row, the number in the diagonal represents the correctly classified instances for that class (i.e `478, 410, 81, 364`).\n",
    "- Off-diagonal elements in each row represent misclassifications (e.g., instances of Spanish being predicted as English, French, or German).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "113f1988-0308-49e0-90a3-2c4b4ea79e41",
   "metadata": {},
   "source": [
    "### Checking for Overfitting and Underfitting\n",
    "\n",
    "To adequately check if the model is overfitting or underfitting, evaluation metrics will be performed on both the `Train` data (i.e data the model has encountered) and the `Test` data (i.e data the model has not encountered). Thereafter, the following indicators will be used to know if there's overfittinng or underfitting.\n",
    "\n",
    "- **Good** evaluation on `Train set` and **Bad** evaluation on `Test set` -- ***Overfitting***\n",
    "- **Good** evaluation on `Train set` and **Good** evaluation on `Test set` -- ***Perfect fitting***\n",
    "- **Good** evaluation on `Train set` and **Better** evaluation on `Test set` -- ***Excellent fitting (and generalization)***\n",
    "- **Bad** evaluation on `Train set` and **Bad** evaluation on `Test set` -- ***Underfitting***\n",
    "\n",
    "**NOTE:** There is always overfitting scenario in most machine learning models (i.e the model is likely to always perform better on the train set than the test set), the aim is to always reduce the degree of overfitting to the barest minimum as possible and to ensure the model generalizes and is robust as much as possible to the test data (i.e unseen data)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1862a017-1bfc-419d-9b09-d7ec14ebc340",
   "metadata": {},
   "source": [
    "##### Using Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "id": "1de25e9d-412a-47ee-8120-acb0e50bbf1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perfect fitting\n",
      "\n",
      "Train Accuracy: 0.9958878504672897 \n",
      "Test Accuracy: 0.9955156950672646 \n"
     ]
    }
   ],
   "source": [
    "test_accuracy = accuracy # sets the value of the previously calculated model accuracy to a new variable \"test_accuracy\"\n",
    "train_accuracy = model.score(X_train, Y_train) # computes the accuracy on the train set\n",
    "accuracy_threshold = 0.80 # sets the minimum accuracy threshold for the model \n",
    "\n",
    "# conditional to check for Excellent fitting\n",
    "if train_accuracy < test_accuracy:\n",
    "    print(f\"Excellent fitting\")\n",
    "\n",
    "# conditional to check for perfect fitting\n",
    "elif train_accuracy >= accuracy_threshold and  test_accuracy >= accuracy_threshold:\n",
    "    print(f\"Perfect fitting\")\n",
    "\n",
    "# conditional to check for over fitting\n",
    "elif train_accuracy > test_accuracy:\n",
    "    print(f\"Over fitting\")\n",
    "\n",
    "# conditional to check for under fitting\n",
    "elif train_accuracy < accuracy_threshold and test_accuracy < accuracy_threshold:\n",
    "    print(f\"Under fitting\")\n",
    "\n",
    "print(f\"\"\"\n",
    "Train Accuracy: {train_accuracy} \n",
    "Test Accuracy: {test_accuracy} \"\"\") # displays the accuracy for the train and test datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "853ba501-a120-4da9-bbb5-62de2207e9ae",
   "metadata": {},
   "source": [
    "##### Using Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "id": "c2930268-5eb8-4a5b-826e-faa820b4b69a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perfect fitting\n",
      "\n",
      "Train Precision: 1.0 \n",
      "Test Precision: 0.9955211387988847 \n"
     ]
    }
   ],
   "source": [
    "test_precision = precision # sets the value of the previously calculated model precision to a new variable \"test_precision\"\n",
    "train_precision = precision_score(Y_test, Y_test, average='weighted') # computes the precision on the train set\n",
    "precision_threshold = 0.67 # sets the minimum precision threshold for the model \n",
    "\n",
    "# conditional to check for Excellent fitting\n",
    "if train_precision < test_precision:\n",
    "    print(f\"Excellent fitting\")\n",
    "\n",
    "# conditional to check for perfect fitting\n",
    "elif train_precision >= precision_threshold and  test_precision >= precision_threshold:\n",
    "    print(f\"Perfect fitting\")\n",
    "\n",
    "# conditional to check for over fitting\n",
    "elif train_precision > test_precision:\n",
    "    print(f\"Over fitting\")\n",
    "\n",
    "# conditional to check for under fitting\n",
    "elif train_precision < precision_threshold and test_precision < precision_threshold:\n",
    "    print(f\"Under fitting\")\n",
    "\n",
    "print(f\"\"\"\n",
    "Train Precision: {train_precision} \n",
    "Test Precision: {test_precision} \"\"\") # displays the precision for the train and test datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4aa5806-1837-4e30-80de-8a8ce7826901",
   "metadata": {},
   "source": [
    "##### Using Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "id": "262e75be-1e2e-4929-a04f-a75df15682b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perfect fitting\n",
      "\n",
      "Train Recall: 1.0 \n",
      "Test Recall: 0.9955156950672646 \n"
     ]
    }
   ],
   "source": [
    "test_recall = recall # sets the value of the previously calculated model recall to a new variable \"test_recall\"\n",
    "train_recall = recall_score(Y_test, Y_test, average = 'weighted') # computes the recall on the train set\n",
    "recall_threshold = 0.67 # sets the minimum recall threshold for the model \n",
    "\n",
    "# conditional to check for Excellent fitting\n",
    "if train_recall < test_recall:\n",
    "    print(f\"Excellent fitting\")\n",
    "\n",
    "# conditional to check for perfect fitting\n",
    "elif train_recall >= recall_threshold and  test_recall >= recall_threshold:\n",
    "    print(f\"Perfect fitting\")\n",
    "\n",
    "# conditional to check for over fitting\n",
    "elif train_recall > test_recall:\n",
    "    print(f\"Over fitting\")\n",
    "\n",
    "# conditional to check for under fitting\n",
    "elif train_recall < recall_threshold and test_recall < recall_threshold:\n",
    "    print(f\"Under fitting\")\n",
    "\n",
    "print(f\"\"\"\n",
    "Train Recall: {train_recall} \n",
    "Test Recall: {test_recall} \"\"\") # displays the recall for the train and test datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d4c5ba6-e1ca-4926-a5c9-8cb3f222363e",
   "metadata": {},
   "source": [
    "##### Using F1-Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "id": "1515582d-e6b5-4f45-8179-0ae79a359cb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perfect fitting\n",
      "\n",
      "Train f1_score: 1.0 \n",
      "Test f1_score: 0.9955158874982464 \n"
     ]
    }
   ],
   "source": [
    "test_f1_score = f1 # sets the value of the previously calculated model f1_score to a new variable \"test_f1_score\"\n",
    "train_f1_score = f1_score(Y_test, Y_test, average= \"weighted\") # computes the f1-score on the train set\n",
    "f1_score_threshold = 0.67 # sets the minimum f1_score threshold for the model \n",
    "\n",
    "# conditional to check for Excellent fitting\n",
    "if train_f1_score < test_f1_score:\n",
    "    print(f\"Excellent fitting\")\n",
    "\n",
    "# conditional to check for perfect fitting\n",
    "elif train_f1_score >= f1_score_threshold and  test_f1_score >= f1_score_threshold:\n",
    "    print(f\"Perfect fitting\")\n",
    "\n",
    "# conditional to check for over fitting\n",
    "elif train_f1_score > test_f1_score:\n",
    "    print(f\"Over fitting\")\n",
    "\n",
    "# conditional to check for under fitting\n",
    "elif train_f1_score < f1_score_threshold and test_f1_score < f1_score_threshold:\n",
    "    print(f\"Under fitting\")\n",
    "\n",
    "print(f\"\"\"\n",
    "Train f1_score: {train_f1_score} \n",
    "Test f1_score: {test_f1_score} \"\"\") # displays the recall for the train and test datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efab37c1-a9cb-4d41-8ced-0af46e94f594",
   "metadata": {},
   "source": [
    "##### Using Confusion Matrix\r",
    "\r\n",
    "When assessing overfitting and underfitting with a confusion matrix, the approach differs from traditional metrics, as there are no specific thresholds to rely on. Instead, we compare the diagonal values of the training and test confusion matrices for each language. This comparison allows us to identify overfitting by examining whether the training accuracy significantly exceeds that of the test set across different languages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "id": "3027325c-74b4-4a6a-b1e5-e21e03077230",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overfitting\n"
     ]
    }
   ],
   "source": [
    "test_conf_matrix = conf_matrix # sets the value (s) of the previously calculated conf_matrix to a new variable \"test_conf_matrix\"\n",
    "train_conf_matrix = confusion_matrix(Y_test, Y_test) # computes the confusion matrix on the train set\n",
    "\n",
    "train_conf_matrix_diag = np.diag(train_conf_matrix) # gets the diagonal values in train_conf_matrix\n",
    "test_conf_matrix_diag = np.diag(test_conf_matrix) # gets the diagonal values in train_conf_matrix\n",
    "\n",
    "# conditional to check for excellent fit\n",
    "if np.all(train_conf_matrix_diag < test_conf_matrix_diag):\n",
    "    print(\"Excellent fit\")\n",
    "\n",
    "# conditional to check for a perfect fit\n",
    "elif np.all(train_conf_matrix_diag > 100) and np.all(test_conf_matrix_diag > 100):\n",
    "    print(\"Perfect Fit\")\n",
    "    \n",
    "# conditional to check for overfitting \n",
    "elif np.any(train_conf_matrix_diag > test_conf_matrix_diag):\n",
    "    print(\"Overfitting\")\n",
    "\n",
    "# conditional to check for underfitting\n",
    "if np.any(train_conf_matrix_diag < 100) and np.all(test_conf_matrix_diag < 100):\n",
    "    print(\"Underfitting\")\n",
    "\n",
    "# converts the train confusion matrix array to a dataFrame for better readability\n",
    "train_confusion_mtrx_df = pd.DataFrame(train_conf_matrix, # the array to be converted to a dataframe\n",
    "                            index=[mapping[i] for i in range(len(mapping))], # acceses each value in the modified mapping dictionary by their corresponding keys and using it to label the rows of the dataframe\n",
    "                            columns=[mapping[i] for i in range(len(mapping))] # acceses each value in the modified mapping dictionary by their corresponding keys and using it to label the columns of the dataframe\n",
    "                           )\n",
    "text_confusion_mtrx_df = confusion_mtrx_df # sets the previous confusion matrix to a new variable \"test_conf_matrix\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09853b18-833b-4b99-a7cc-131f5adbbb4e",
   "metadata": {},
   "source": [
    "##### Observation\n",
    "\n",
    "By using the confusion matrix, an overfitting result was gotten because from the diagonal vectors of the two matrices, the train set had more True Positives for German Language that test set had on the same language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "id": "04cd8add-7821-48ad-9140-537f33ad9c7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>English</th>\n",
       "      <th>French</th>\n",
       "      <th>German</th>\n",
       "      <th>Spanish</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>English</th>\n",
       "      <td>477</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>French</th>\n",
       "      <td>0</td>\n",
       "      <td>403</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>German</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>94</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Spanish</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>364</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         English  French  German  Spanish\n",
       "English      477       0       0        0\n",
       "French         0     403       0        0\n",
       "German         0       0      94        0\n",
       "Spanish        0       0       0      364"
      ]
     },
     "execution_count": 480,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_confusion_mtrx_df # displays the train confusion matrix dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "id": "7bbf45d1-0807-41d2-ba09-a01d8ef8a375",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>English</th>\n",
       "      <th>French</th>\n",
       "      <th>German</th>\n",
       "      <th>Spanish</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>English</th>\n",
       "      <td>476</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>French</th>\n",
       "      <td>1</td>\n",
       "      <td>401</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>German</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>93</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Spanish</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>362</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         English  French  German  Spanish\n",
       "English      476       1       0        0\n",
       "French         1     401       0        1\n",
       "German         1       0      93        0\n",
       "Spanish        1       0       1      362"
      ]
     },
     "execution_count": 481,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_confusion_mtrx_df # displays the test confusion matrix dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "700960b8-b2d8-48e4-a7e0-6a2646593303",
   "metadata": {},
   "source": [
    "### Hyper-parameter Tuning:\n",
    "\n",
    "From the evaluation metrics obtained, it is evident that the performance of the Multinomial Naive Bayes model was very good. However, for any future adjustments and potential improvements, hyperparameter tuning can be beneficial. The following hyperparameters can be tuned using techniques such as GridSearchCV:\n",
    "\n",
    "- **alpha (Laplace Smoothing)**: This parameter adjusts the smoothing of probabilities, which can help address zero-frequency issues.\n",
    "- **fit_prior**: This determines whether to learn class prior probabilities based on the training data.\n",
    "- **class_prior**: Allows for setting custom class prior probabilities when `fit_prior` is set to `False`.\n",
    "\n",
    "Implementing GridSearchCV will enable an exhaustive search over specified parameter values, helping to identify the optimal settings for enhancing model performance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e100c8dd-e9f8-4aa1-b5f1-c4f9e7038085",
   "metadata": {},
   "source": [
    "##### Using GridSearchCV to get the Best Hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "id": "d8c4df9d-9106-450c-a6b2-f0f39533add7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'alpha': 0.1, 'fit_prior': False}\n",
      "Best Cross-Validation Accuracy: 0.9931\n"
     ]
    }
   ],
   "source": [
    "\n",
    "mnb = MultinomialNB() # initializes the model\n",
    "\n",
    "# sets up the parameter grid for tuning\n",
    "param_grid = {\n",
    "    'alpha': [0.1, 0.5, 1.0, 1.5, 2.0],  # laplace smoothing\n",
    "    'fit_prior': [True, False]           # whether to learn class prior probabilities\n",
    "}\n",
    "\n",
    "# initializes GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=mnb, # specifies the model to use\n",
    "                           param_grid=param_grid, # the range of hyper-parameter to be tested\n",
    "                           scoring='accuracy', # evaluation metric to decidd best hyperparameters\n",
    "                           cv=5, # number of cross validations\n",
    "                           n_jobs=1 # sets only one CPU core for sequential running. -1 -- parallel runnig.\n",
    "                          )\n",
    "\n",
    "# fits the model with the training data\n",
    "grid_search.fit(X_train, Y_train)\n",
    "\n",
    "# gets the best parameters and best score\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "print(f\"Best Parameters: {best_params}\") # prinst the best parameters after trying out the training with grid search\n",
    "print(f\"Best Cross-Validation Accuracy: {best_score:.4f}\") # prints best_score to 4dp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f7571a3-20b8-41e3-b460-a2b24f108221",
   "metadata": {},
   "source": [
    "### Feature Imporance\n",
    "\n",
    "In language detection using **Multinomial Naive Bayes (MNB)**, feature importance is not commonly emphasized for the following reasons:\n",
    "\n",
    "1. **Model Nature**: MNB relies on the assumption that features (e.g., words) are conditionally independent given the class (language). The model does not calculate a global importance score for features. Instead, it calculates the probability of each feature occurring in each class, making feature importance less relevant.\n",
    "\n",
    "2. **Focus on Word Frequencies**: The MNB model is driven by word frequencies or counts, and its performance depends on the relative frequencies of words across languages rather than the overall importance of any single feature.\n",
    "\n",
    "3. **Class-Specific Feature Probabilities**: For MNB, each word contributes differently to each language. Therefore, the model focuses on conditional probabilities (i.e., likelihoods) of features within each class rather than assigning a single importance score to features across all classes.\n",
    "\n",
    "4. **Interpretability**: While feature importance can be useful in some models (e.g., decision trees or logistic regression), in language detection tasks using MNB, analyzing the likelihoods of features (words) per class provides more meaningful insights into which words are most indicative of specific languages, rather than measuring importance in a global sense.\n",
    "\n",
    "In summary, feature importance is not a priority in MNB for language detection, as the model is designed to use the relative frequency of words to predict language, focusing on class-specific probabilities instead.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9705afc1-05b2-4e57-878c-b5f356e1d33c",
   "metadata": {},
   "source": [
    "### Model Deployment\n",
    "With a satisfory model performance, the model will be saved for future use. This can be done using libraries like `joblib` or `pickle`, which allow us to serialize the model and load it later for deployment without retraining."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "id": "3c1ddd8a-bc70-4012-94bd-1420feaee39a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Rizama-Victor-Samuel-Language-Detection-Model.pkl']"
      ]
     },
     "execution_count": 487,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(model, 'Rizama-Victor-Samuel-Language-Detection-Model.pkl') # saves the model in the current code working directory"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
